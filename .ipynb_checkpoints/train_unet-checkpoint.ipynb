{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Cropping2D, ZeroPadding2D, Convolution2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard\n",
    "from keras import backend as K\n",
    "\n",
    "working_path = \"/disk1/luna16/output/\"\n",
    "\n",
    "K.set_image_dim_ordering('th')  # Theano dimension ordering in this code\n",
    "BATCH_SIZE=4\n",
    "EPOCHS=1\n",
    "img_rows = 512\n",
    "img_cols = 512\n",
    "\n",
    "smooth = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_np(y_true,y_pred):\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = np.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inputs = Input((1, img_rows, img_cols))\n",
    "\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4], axis=1)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv3], axis=1)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2], axis=1)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1], axis=1)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=conv10)\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=1.0e-5), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict(use_existing):\n",
    "    print('-'*30)\n",
    "    print('Loading and preprocessing train data...')\n",
    "\n",
    "    imgs_train = np.load(working_path+\"trainImages.npy\").astype(np.float32)\n",
    "    imgs_mask_train = np.load(working_path+\"trainMasks.npy\").astype(np.float32)\n",
    "    \n",
    "    imgs_test = np.load(working_path+\"valImages.npy\").astype(np.float32)\n",
    "    imgs_mask_test_true = np.load(working_path+\"valMasks.npy\").astype(np.float32)\n",
    "    \n",
    "    imgs_test = np.load(working_path+\"testImages.npy\").astype(np.float32)\n",
    "    imgs_mask_test_true = np.load(working_path+\"testMasks.npy\").astype(np.float32)\n",
    "    \n",
    "    mean = np.mean(imgs_train)  # mean for data centering\n",
    "    std = np.std(imgs_train)  # std for data normalization\n",
    "\n",
    "    imgs_train -= mean  # images should already be standardized, but just in case\n",
    "    imgs_train /= std\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Creating and compiling model...')\n",
    "\n",
    "    model = get_model()\n",
    "    # Saving weights to unet.hdf5 at checkpoints\n",
    "    model_checkpoint = ModelCheckpoint('best_unet.hdf5', monitor='loss', save_best_only=True)\n",
    "    tb = TensorBoard(log_dir=\"logs\", batch_size=BATCH_SIZE)\n",
    "    # Set argument for call to train_and_predict to true at end of script\n",
    "    if use_existing:\n",
    "        print('loading weights...')\n",
    "        model.load_weights('../unet.hdf5')\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Fitting model...')\n",
    "\n",
    "    model.fit(imgs_train, imgs_mask_train, \n",
    "              validation_data=(imgs_val, imgs_mask_val),\n",
    "              batch_size=BATCH_SIZE, \n",
    "              epochs=EPOCHS, \n",
    "              verbose=1, shuffle=True,\n",
    "              callbacks=[model_checkpoint,tb])\n",
    "\n",
    "    # loading best weights from training session\n",
    "    print('-'*30)\n",
    "    print('Loading saved weights...')\n",
    "\n",
    "    model.load_weights('../unet.hdf5')\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Predicting masks on test data...')\n",
    "\n",
    "    num_test = len(imgs_test)\n",
    "    imgs_mask_test = np.ndarray([num_test,1,512,512],dtype=np.float32)\n",
    "    for i in range(num_test):\n",
    "        imgs_mask_test[i] = model.predict([imgs_test[i:i+1]], verbose=0)[0]\n",
    "    np.save('masksTestPredicted.npy', imgs_mask_test)\n",
    "    mean = 0.0\n",
    "    for i in range(num_test):\n",
    "        mean+=dice_coef_np(imgs_mask_test_true[i,0], imgs_mask_test[i,0])\n",
    "    mean/=num_test\n",
    "    \n",
    "    print(\"Mean Dice Coeff : \", mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Loading and preprocessing train data...\n",
      "------------------------------\n",
      "Creating and compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:38: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1, (1, 1), activation=\"sigmoid\")`\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights...\n",
      "------------------------------\n",
      "Fitting model...\n",
      "Epoch 1/1\n",
      "2533/2533 [==============================] - 470s 185ms/step - loss: -0.0775 - dice_coef: 0.0775\n",
      "------------------------------\n",
      "Loading saved weights...\n",
      "------------------------------\n",
      "Predicting masks on test data...\n",
      "Mean Dice Coeff :  0.3261805575952434\n"
     ]
    }
   ],
   "source": [
    "train_and_predict(True)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
